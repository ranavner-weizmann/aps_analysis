{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05179fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import importlib.util\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../code/src/')\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33695f",
   "metadata": {},
   "source": [
    "#### CSV creation from stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27fcf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avnerran/MSc/aps_analysis/transformers/notebooks/../code/src/utils.py:27: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  ts_col = df[0][0:last_raw_i]\n"
     ]
    }
   ],
   "source": [
    "# Shamat\n",
    "shamat_df = utils.get_df_from_shamat_csv('../data/raw/shamat/shamat_beit_dagan.csv')\n",
    "radiation_df = utils.get_df_from_radiation_csv(('../data/raw/shamat/radiation_beit_dagan.csv'))\n",
    "shamat_df['rad'] = radiation_df['rad']\n",
    "\n",
    "if not os.path.exists('../data/processed_csvs/'):\n",
    "    os.makedirs('../data/processed_csvs/')\n",
    "shamat_df.to_csv('../data/processed_csvs/shamat.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17640 entries, 2023-05-01 00:00:00 to 2023-08-31 12:00:00\n",
      "Data columns (total 19 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   shamat_P                       17640 non-null  float64\n",
      " 1   shamat_RH                      17640 non-null  float64\n",
      " 2   shamat_T                       17640 non-null  float64\n",
      " 3   shamat_T_ground                17640 non-null  float64\n",
      " 4   shamat_T_max                   17640 non-null  float64\n",
      " 5   shamat_T_min                   17638 non-null  float64\n",
      " 6   shamat_precipitation           17640 non-null  float64\n",
      " 7   shamat_wind_direction          17630 non-null  float64\n",
      " 8   shamat_wind_direction_std_dev  17630 non-null  float64\n",
      " 9   shamat_wind_gust_direction     17630 non-null  float64\n",
      " 10  shamat_wind_gust_speed         17630 non-null  float64\n",
      " 11  shamat_wind_speed              17630 non-null  float64\n",
      " 12  shamat_wind_speed_10min_max    17630 non-null  float64\n",
      " 13  shamat_wind_speed_1min_max     17630 non-null  float64\n",
      " 14  shamat_U                       17630 non-null  float64\n",
      " 15  shamat_V                       17630 non-null  float64\n",
      " 16  shamat_U_corrected             17630 non-null  float64\n",
      " 17  shamat_V_corrected             17630 non-null  float64\n",
      " 18  rad                            17580 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "shamat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd35072",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_w_f0 = 0\n",
    "station_wo_f0 = 0\n",
    "\n",
    "for file in os.listdir('../data/raw/ep/'):\n",
    "    if file.endswith('.xlsx'):\n",
    "        station_df = utils.get_df_from_excel_station_file(f'../data/raw/ep/{file}')\n",
    "\n",
    "        # adding the factor0 to the csv:\n",
    "        try:\n",
    "            station_df['factor0'] = utils.calculate_factor0(station_df, shamat_df)\n",
    "            if station_df['factor0'].notna().any():\n",
    "                stations_w_f0 += 1\n",
    "            else:\n",
    "                station_wo_f0 += 1\n",
    "            station_df.to_csv(f'../data/processed_csvs/{file[:-5]}.csv', index=True)\n",
    "            \n",
    "        except:\n",
    "            print(f'probably no measurement for the factor calculation in station: {file[:-5]}')\n",
    "            station_df.to_csv(f'../data/processed_csvs/{file[:-5]}.csv', index=True)\n",
    "            \n",
    "            continue\n",
    "\n",
    "print(f'total num of station: {stations_w_f0 + station_wo_f0}')\n",
    "print(f'num of stations with factor0: {stations_w_f0}')\n",
    "print(f'num of stations without factor0: {station_wo_f0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " the dates of the sessions are:\n",
    "\n",
    "4-5 May 2023\n",
    "8-9 May 2023\n",
    "23-24 May 2023\n",
    "\n",
    "25-26 August 2023\n",
    "28-29 August 2023\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f670db",
   "metadata": {},
   "source": [
    "#### Pulling timestamps from pop tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f33157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the time of the flights:\n",
    "# the time in the list is the time at the center of the flight\n",
    "flight_times = torch.load('../data/raw/drone/pom_timestamps.pt', map_location='cpu', weights_only=False)\n",
    "flight_time_list = flight_times.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b0fd3",
   "metadata": {},
   "source": [
    "#### Saving the stations as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/station_tensors/'):\n",
    "    os.makedirs('../data/station_tensors/')\n",
    "\n",
    "\n",
    "for station in os.listdir('../data/processed_csvs/'):\n",
    "    if 'shamat' in station:\n",
    "        continue\n",
    "    if station.endswith('.csv'):\n",
    "        t = utils.station_csv_to_tensor(f'../data/processed_csvs/{station}', flight_time_list, max_features=20, max_measurements=5)\n",
    "        torch.save(t, f'../data/station_tensors/{station[:-4]}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2595de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tensors shapes are [P, L, Fs, M]: [66, 5, 20, 5] when the missing features and measurements per feature are nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking tensors integrity\n",
    "tmp_t = torch.load('../data/station_tensors/ashdod_kala.pt')\n",
    "tmp_t[1,1,:,:]\n",
    "\n",
    "# we can see that we have nans when full features are missing and when some measurements are missing. vi!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7abb7",
   "metadata": {},
   "source": [
    "#### Creating the metadata json files for each stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2492f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in os.listdir('../data/processed_csvs/'):\n",
    "    if station.endswith('.csv'):\n",
    "        station = station[:-4]\n",
    "        meta = utils.save_tensor_metadata(f\"../data/processed_csvs/{station}.csv\", station, tensor_shape=[[66, 5, 20, 5]], output_dir='../data/metadata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2926037",
   "metadata": {},
   "source": [
    "Now we have a tensor for each station: [P, L, Fs, M].  \n",
    "Plus a metadata json file for each station.  \n",
    "\n",
    "Plus, we have the tensor of the Ozone measurements: [P, h, Fd]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
